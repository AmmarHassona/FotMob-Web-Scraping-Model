# -*- coding: utf-8 -*-
"""FotMob Player WebScraping Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PY3uM0vvI-DOALugdl9aGnzA1w1_MdOI
"""

import requests

import pandas as pd
from pandas import json_normalize

info_params = {
    'id': '1077894',
}

info_url = 'https://www.fotmob.com/api/playerData'

# Load data using json normalize
# The point of the method and extra code is to ensure that the data is loaded consistently every time
def load_player_info(url , params):
    with requests.Session() as session:
        try:
            # Get the player information
            response = session.get(info_url , params = params)
            response.raise_for_status()
            data = response.json()

            # Extract player information
            player_info = data.get('playerInformation' , {})
            info_df = json_normalize(player_info)

            # Extract player name
            player_name = data.get('name')
            return info_df , player_name  # Return both DataFrame and player name as a tuple
        except requests.exceptions.RequestException as e:
            print(f"Error loading data: {e}")
    return pd.DataFrame() , None  # Return empty DataFrame and None for player name if there's an error

# Call load_data method and drop all NaN values for columns that meet the threshold
info_df , player_name = load_player_info(info_url , info_params)
info_df = info_df.dropna(axis = 1 , thresh = len(info_df) * 0.9)

# Rename columns and drop translationKey column
info_df = info_df.rename(columns={'title' : 'Title' , 'value.fallback' : 'Info'})
info_df = info_df.drop(columns = ['translationKey'])

# Add player's name as a new row
info_df.loc[len(info_df)] = ['Name' , player_name]

file_name = f"{player_name.replace(' ', '_')}_Player_Info.csv"
info_df.to_csv(file_name , index = False , encoding = 'utf-8-sig')

info_df

# change url and params due to the data being in a different api
stats_params = {
    'playerId': '1077894',
    'seasonId': '2023/2024-87',
}

stats_url = 'https://www.fotmob.com/api/playerStats'

# repeat the method used to get the player data
def load_stats(url , params):
    with requests.Session() as session:
        try:
            response = session.get(url , params = params)
            response.raise_for_status()
            data = response.json()

            # since the data is nested multiple times, we will run a for loop to iterate over all of the nested keys
            player_stats = data.get('statsSection' , {}).get('items' , [])
            all_stats = []
            for item in player_stats:
                inner_key = item.get('items' , [])
                for item in inner_key:
                    all_stats.append(item)

            stats_df = json_normalize(all_stats)

            return stats_df
        except requests.exceptions.RequestException as e:
            print(f"Error loading data: {e}")
    return pd.DataFrame()

stats_df = load_stats(stats_url , stats_params)
stats_df = stats_df.rename(columns = {'title' : 'Title' , 'localizedTitleId' : 'Text' , 'statValue' : 'Stat' , 'per90' : 'statPer90' , 'percentileRank' : 'Percentile' , 'percentileRankPer90' : 'percentilePer90'})
stats_df = stats_df.drop(columns = ['statFormat'])

file_name = f"{player_name.replace(' ', '_')}_Player_Stats.csv"
stats_df.to_csv(file_name , index = False , encoding = 'utf-8-sig')

stats_df

stats_params = {
    'playerId': '1077894',
    'seasonId': '2023/2024-87',
}

stats_url = 'https://www.fotmob.com/api/playerStats'

# repeat the method used to get the player data
def load_shotmap(url, params):
    with requests.Session() as session:
        try:
            response = session.get(url, params=params)
            response.raise_for_status()
            data = response.json()

            shotmap = data.get('shotmap' , {})
            shots_df = json_normalize(shotmap)

            return shots_df
        except requests.exceptions.RequestException as e:
            print(f"Error loading data: {e}")
    return pd.DataFrame()

shots_df = load_shotmap(stats_url, stats_params)
shots_df = shots_df.drop(columns = ['goalCrossedY' , 'goalCrossedZ' , 'homeTeamId' , 'homeScore' , 'awayTeamId' , 'id' , 'playerId' , 'playerName' , 'teamColor' , 'teamColorDark' , 'teamId'])
shots_df = shots_df.drop(columns = ['onGoalShot.zoomRatio' , 'minAdded' , 'awayScore'])
shots_df = shots_df.drop(columns = ['box'])
shots_df = shots_df.drop(columns = ['isSavedOffLine'])
shots_df = shots_df.drop(columns = ['matchId'])

shots_df = shots_df.rename(columns = {
    'eventType' : 'Type' ,
    'min' : 'Minute' ,
    'expectedGoals' : 'xG' ,
    'expectedGoalsOnTarget' : 'onTargetxG' ,
    'isFromInsideBox' : 'insideBox' ,
    'onGoalShot.x' : 'onGoalShotX' ,
    'onGoalShot.y' : 'onGoalShotY' ,
    'period' : 'Half'
})

file_name = f"{player_name.replace(' ', '_')}_Player_Shots.csv"
shots_df.to_csv(file_name , index = False , encoding = 'utf-8-sig')

shots_df